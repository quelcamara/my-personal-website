{"props":{"pages":[{"__metadata":{"id":"content\\pages\\about.md","source":"sourcebit-source-filesystem","sourceName":"pages","sourcePath":"content/pages","relSourcePath":"about.md","relProjectPath":"content\\pages\\about.md","modelType":"page","modelName":"page","modelLabel":"Page","urlPath":"/about"},"frontmatter":{"title":"About Me","subtitle":"I am so glad to have you here!","img_path":"images/about.jpg","seo":{"title":"About Me","description":"A page about me and my work","extra":[{"name":"og:type","value":"website","keyName":"property"},{"name":"og:title","value":"About Me","keyName":"property"},{"name":"og:description","value":"A page about me and my work","keyName":"property"},{"name":"og:image","value":"images/about.jpg","keyName":"property","relativeUrl":true},{"name":"twitter:card","value":"summary_large_image"},{"name":"twitter:title","value":"About Me"},{"name":"twitter:description","value":"A page about me and my work"},{"name":"twitter:image","value":"images/about.jpg","relativeUrl":true}]},"layout":"page"},"markdown":"\nWelcome to the most beginner-friendly blog on **Data Science** you will ever see! Hope you are ready to go into the hotter topics on **Data Analysis**, **Machine Learning**, **Artificial Inteligence**, and so many other exciting stuff about technology and programming without getting all chaotic about those hard and complex book definitions.\n\nSo let us not take it too long!</br>\nBut first, let me introduce myself properly.\n\nI am a former Designer and Civil Engineer who ended up falling in love with Data Science after a long time struggling to decide if I should keep on following the path I had once begun, or if I should just throw it all away and follow my heart into something I could finally see myself in. I know it might sound a little cheesy at some point, but that's what it is.  \n\nI am a very curious person, and when I first dumped into Data Science, it was such a completely new world for me that I found myself unbearable amazed by the so many things I felt I just *needed* to know right away.\n\n>Any sufficiently advanced technology is indistinguishable from magic. <cite>Arthur C. Clarke</cite>\n\n So here we are!\n\nWhen I decided I wanted to keep track of my progress I found that building a blog would be just the perfect beginning. That's because here I can not only keep my records about the things I am most recently studying, but I can also improve some communication skills, and - last but not least! - maybe I am able to help other people, in the near future, who are also starting their jorney into Data Science.\n\nNo changing of career is easy as it seems. It demands a lot of effort and resilience from you to start all over again. And that's why I am here! I hope this blog finds you in a perfect timing so you don't give up on following the path you've been dreaming.\n\n*Be very welcome and enjoy your stay!* 游눹\n"},{"__metadata":{"id":"content\\pages\\contact.md","source":"sourcebit-source-filesystem","sourceName":"pages","sourcePath":"content/pages","relSourcePath":"contact.md","relProjectPath":"content\\pages\\contact.md","modelType":"page","modelName":"contact","modelLabel":"Contact","urlPath":"/contact"},"frontmatter":{"title":"Get in Touch","img_path":"images/contact.jpg","form_id":"contactForm","form_action":"/success","form_fields":[{"input_type":"text","name":"name","label":"Name","default_value":"Your name","is_required":true},{"input_type":"email","name":"email","label":"Email","default_value":"Your email address","is_required":true},{"input_type":"select","name":"subject","label":"Subject","default_value":"Please select","options":["Get in touch","Post suggestions","Partnership","Error on the site","Other"]},{"input_type":"textarea","name":"message","label":"Message","default_value":"Your message"},{"input_type":"checkbox","name":"consent","label":"I understand that this form is storing my submitted information so I can be contacted."}],"submit_label":"Send Message","seo":{"title":"Get in Touch","description":"This is the contact page","extra":[{"name":"og:type","value":"website","keyName":"property"},{"name":"og:title","value":"Get in Touch","keyName":"property"},{"name":"og:description","value":"This is the contact page","keyName":"property"},{"name":"og:image","value":"images/contact.jpg","keyName":"property","relativeUrl":true},{"name":"twitter:card","value":"summary_large_image"},{"name":"twitter:title","value":"Get in Touch"},{"name":"twitter:description","value":"This is the contact page"},{"name":"twitter:image","value":"images/contact.jpg","relativeUrl":true}]},"layout":"contact"},"markdown":"\nTo get in touch fill the form below.\n"},{"__metadata":{"id":"content\\pages\\index.md","source":"sourcebit-source-filesystem","sourceName":"pages","sourcePath":"content/pages","relSourcePath":"index.md","relProjectPath":"content\\pages\\index.md","modelType":"page","modelName":"home","modelLabel":"Home","urlPath":"/"},"frontmatter":{"title":"Home","has_more_link":true,"more_link_text":"Keep reading","seo":{"title":"Raquel C칙mara - Data Scientist","description":"A Data Scientist Diary","extra":[{"name":"og:type","value":"website","keyName":"property"},{"name":"og:title","value":"Stackbit Fjord Theme","keyName":"property"},{"name":"og:description","value":"A Data Scientist Diary","keyName":"property"},{"name":"og:image","value":"images/home.jpg","keyName":"property","relativeUrl":true},{"name":"twitter:card","value":"summary_large_image"},{"name":"twitter:title","value":"Stackbit Fjord Theme"},{"name":"twitter:description","value":"A Data Scientist Diary"},{"name":"twitter:image","value":"images/home.jpg","relativeUrl":true}]},"layout":"home"},"markdown":""},{"__metadata":{"id":"content\\pages\\portfolio.md","source":"sourcebit-source-filesystem","sourceName":"pages","sourcePath":"content/pages","relSourcePath":"portfolio.md","relProjectPath":"content\\pages\\portfolio.md","modelType":"page","modelName":"page","modelLabel":"Page","urlPath":"/portfolio"},"frontmatter":{"title":"Portfolio","subtitle":"Topic under construction.","img_path":"images/portfolio.jpg","seo":{"title":"Portfolio","description":"My data science portfolio","extra":[{"name":"og:type","value":"website","keyName":"property"},{"name":"og:title","value":"Portfolio","keyName":"property"},{"name":"og:description","value":"My data science portfolio","keyName":"property"},{"name":"og:image","value":"images/portfolio.jpg","keyName":"property","relativeUrl":true},{"name":"twitter:card","value":"summary_large_image"},{"name":"twitter:title","value":"Portfolio"},{"name":"twitter:description","value":"My data science portfolio"},{"name":"twitter:image","value":"images/portfolio.jpg","relativeUrl":true}]},"layout":"page"},"markdown":""},{"__metadata":{"id":"content\\pages\\posts\\3-mighty-libraries-for-a-data-science-beginner-to-become-friends-with-part-1.md","source":"sourcebit-source-filesystem","sourceName":"pages","sourcePath":"content/pages","relSourcePath":"posts\\3-mighty-libraries-for-a-data-science-beginner-to-become-friends-with-part-1.md","relProjectPath":"content\\pages\\posts\\3-mighty-libraries-for-a-data-science-beginner-to-become-friends-with-part-1.md","modelType":"page","modelName":"post","modelLabel":"Post","urlPath":"/posts/3-mighty-libraries-for-a-data-science-beginner-to-become-friends-with-part-1"},"frontmatter":{"title":"3 mighty libraries for a Data Science beginner to become friends with (part 1)","subtitle":"I will tell you the secret for this friendship to work, and why you should stick with them forever.","excerpt":"It is very common to get confused about what we should learn at the very beginning of our studies. But no need to start yelling at a cat! I am sure that after these posts you will be gifted with plenty of working for the next few days. On this first section out of three posts, we'll discover the strength of Pandas.","date":"2021-04-23","thumb_img_path":"images/post-2/cover.jpg","thumb_img_alt":"migthy libraries","content_img_path":"images/post-2/cover.jpg","seo":{"title":"3 mighty libraries for a Data Science beginner to become friends with (part 1)","description":"I will tell you the secret for this friendship to work, and why you should stick with them forever.","extra":[{"name":"og:type","value":"article","keyName":"property"},{"name":"og:title","value":"3 mighty libraries for a Data Science beginner to become friends with (part 1)","keyName":"property"},{"name":"og:description","value":"I will tell you the secret for this friendship to work, and why you should stick with them forever.","keyName":"property"},{"name":"og:image","value":"images/post-2/cover.jpg","keyName":"property","relativeUrl":true},{"name":"twitter:card","value":"summary_large_image"},{"name":"twitter:title","value":"3 mighty libraries for a Data Science beginner to become friends with (part 1)"},{"name":"twitter:description","value":"I will tell you the secret for this friendship to work, and why you should stick with them forever."},{"name":"twitter:image","value":"images/post-2/cover.jpg","relativeUrl":true}]},"layout":"post"},"markdown":"\r\nI understand you.\r\n\r\nWhen we start something new, we use to get so excited that we begin to google search a lot of random stuff about that thing. And it becomes almost inevitable not to get lost on the endless sea of information available on the internet. But by putting some effort, we are able to filter what is important to know based on our current level.\r\n\r\nOn this set of posts, you will be given precious information about three **python** libraries that you should definitely look up:\r\n\r\n- Pandas\r\n- NumPy\r\n- Matplotlib\r\n\r\nYou probably already heard a thing or two about any of these. But if you didn't pay attention before - because maybe you thought they were not worth it - this is your chance to redeem yourself.\r\n\r\nTo better illustrate the next topics, consider the following dataset for demonstration purposes:\r\n\r\n&nbsp; | PurchaseDate |   Region  |   State   | Seller |  Item   | Units | UnitPrice  \r\n:-----:| :-----------:| :--------:| :--------:| :-----:| :------:| :----:| :-------:\r\n   0   | 10-Jun-2020  | Northeast |   Bahia   | Tobias | Stove   |  62   |  400.99\r\n   1   | 11-Jun-2020  | Southeast | S칚o Paulo | Nadia  | Fridge  |  29   |  100.99\r\n   2   |  3-Aug-2020  | Northeast |   Cear치   | Carlos | Stove   |  55   | 1200.49\r\n   3   | 22-Aug-2020  | Northeast |   Bahia   | Pedro  | Fridge  |  81   | 1900.99\r\n   4   | 26-Aug-2020  |  Midwest  |   Goi치s   | Tania  | Blender |  42   | 2300.95\r\n   5   | 10-Sep-2020  | Northeast |  Sergipe  | Tobias | Carpet  |  35   |  400.99\r\n   6   | 12-Sep-2020  |   North   |   Par치    | Carlos | Carpet  |   3   | 2750.00\r\n   7   |  7-Oct-2020  | Northeast |  Sergipe  | Nadia  | Blender |   2   | 1250.00\r\n   8   | 15-Oct-2020  |   North   | Amazonas  | Pedro  | Stove   |   7   | 1000.29\r\n   9   | 27-Nov-2020  | Southeast | S칚o Paulo | Nadia  | Fridge  |  16   | 1500.99\r\n  10   | 13-Dec-2020  |   South   |  Paran치   | Tania  | Blender |  76   | 1450.99\r\n\r\n***file:*** order_data.csv\r\n\r\nOn this first post, we'll start with **Pandas**. And if you want to check on some specific functionality, I will leave you the table below so you can also go straight to the point.\r\n\r\n|    Load and Transform     |     Visualize     |           Locate           |       Summarize       |  \r\n:-------------------------: | :---------------: | :------------------------: | :-------------------: | \r\n[read_csv](#read-csv)       | [head](#head)     | [loc](#loc)                | [describe](#describe) |\r\n[read_excel](#read-excel)   | [tail](#tail)     | [iloc](#iloc)              | [info](#info)         |\r\n[sort_values](#sort-vals)   | [shape](#shape)   | [duplicated](#duplic)      | [sum](#sum)           |\r\n[set_index](#set-index)     | [index](#index)   | [query](#query)            | [count](#count)       |\r\n[reset_index](#reset-idx)   | [columns](#cols)  | [df['col']](#df-col1)      | [min](#min)           |\r\n[drop](#drop)               | [dtypes](#dtypes) | [df.your_col](#df-col2)    | [max](#max)           |\r\n[copy](#copy)               | [isnull](#isnull) |          ---               | [mean](#mean)         |\r\n---                         | [values](#values) |          ---               | [median](#median)     |\r\n---                         |        ---        |          ---               | [corr](#corr)         |\r\n\r\n\r\n## Pandas\r\n![Panda](../../images/post-2/01-panda.jpg)\r\n***image*** by [Eric Baccega](https://onebigphoto.com/giant-panda-sleeping-on-a-tree-china/)\r\n\r\nPandas is a very powerful python library widely used by data scientists and/or analysts for both manipulating and analysing data. It also works well with many other python modules, and its main advantage is having  an intuitive and practical usability without compromising its functionality.\r\n\r\nFor convenience, pandas use to be loaded into the project with the allias `pd`, as shown below:\r\n\r\n~~~python\r\nimport pandas as pd\r\n\r\n~~~\r\n\r\nIt is useful so we can just use this short allias instead of typing the whole package name every time we want to use a pandas function. This library also allows us to create two type of structures that make the manipulating easier: **Series** and **Dataframes**.\r\n\r\n#### Series\r\nAccording to pandas official [documentation](https://pandas.pydata.org/docs/index.html), a series is a one-dimensional ndarray (an array that belongs to the NumPy class `ndarray`) with axis labels.\r\n\r\n*Omg, this...*\r\n\r\nBetter saying, a pandas series is nothing but an unidimensional array (having a unique dimension) which can store any sort of data with labels or indexes as the axis. In short, it is like a column of a dataframe. Let's see how to create a series in pandas and how to identify its structure. The following code can be replicated in your jupyter notebook:\r\n\r\n~~~python\r\n# imports\r\nIn [1]: import pandas as pd\r\n\r\n# creates a series to store people names\r\nIn [2]: names = pd.Series(['Carlos', 'Sara', 'Louise', 'James'])\r\n\r\nIn [3]: names\r\nOut[3]: 0   Carlos\r\n        1     Sara\r\n        2   Louise\r\n        3    James\r\n        dtype: object\r\n\r\n~~~\r\n\r\nNote that, as indexation in python begins with 0, the index range of the series created goes from 0 to `n-1`, where *n* is the number of elements on your series. This is a very important thing to remember, and which might cause a lot of malfunctioning on your codes if you mess that up.\r\n\r\nWe can also see that, as I haven't specified any index range for my series, pandas automaticatly insert the standard indexation. However, if I want a different label for my axis, I can specify that when creating the object. See how it looks:\r\n\r\n~~~python\r\n# creates a series to store animals species\r\nIn [2]: animals = pd.Series(['Dog', 'Elephant', 'Fox', 'Eagle'],\r\n                            index=['A', 'B', 'C', 'D'])\r\n\r\nIn [3]: animals\r\nOut[3]: A        Dog\r\n        B   Elephant\r\n        C        Fox\r\n        D      Eagle\r\n        dtype: object\r\n\r\n~~~\r\n\r\nThese are, in fact, very simple examples. But they might help you having an ideia of what a series look like.\r\n\r\n#### Dataframes\r\nDifferently from a series, a pandas dataframe is a two-dimensional tabular structure where data is labeled by its own combination of column and row. This structure is size-mutable and potentially heterogeneous. That is, we can easily create a dataframe with two columns and two rows, and then add new columns and rows for this same object. And we can store different types of data on the same dataframe, which can be very convinient in many situations.\r\n\r\nLet's see how it works on the jupyter notebook:\r\n\r\n~~~python\r\n# imports\r\nIn [1]: import pandas as pd\r\n\r\n# creates a dataframe to store people names, ages, and heights\r\nIn [2]: names = pd.DataFrame([['Carlos', 27, 1.78], ['Sara', 12, 1.35],\r\n                              ['Louise', 35, 1.62], ['James', 18, 1.87]],\r\n                              columns=['name', 'age', 'height'],\r\n                              index=['i', 'ii','iii', 'iv'])\r\n\r\nIn [3]: names\r\nOut[3]:      name   age   height\r\n        i  Carlos    27     1.78\r\n       ii    Sara    12     1.35\r\n      iii  Louise    35     1.62\r\n       iv   James    18     1.87\r\n~~~\r\n\r\nCould you notice how they differ? Now we have a table storing a set of information that we can either access by the index - returning all the information in a the row - or by the combination of index and columns - returning a single desired value.\r\n\r\nAnd if we just want to go on regular indexing, we only need to remove the `index` attribute from the function.\r\n\r\nSee the official [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) for more information.\r\n\r\nJust so to remind you, all the operations from now on will take into consideration the dataset we defiined on the very beginning of this post. Also, see that you will face many abbreviations and acronyms on your way through the data science world. I will provide you a cheatsheet on later posts. \r\n\r\nNow, let us finally see what pandas can bring us!\r\n\r\n#### Loading data\r\nPandas has many functions to load data into your project. You can mine data from a csv - a text file - or an excel spreadsheet, for instance. But it is also possible to get information from SQL and HTML tables, SQL query, JSON strings, Google BigQuery, Stata .dta files, and so on. See [here](https://pandas.pydata.org/docs/reference/io.html) all the options pandas offers.\r\n\r\nHere are two frequently used functions:\r\n\r\n<a id=\"read-csv\"></a>\r\n###### pd.read_csv\r\nFor comma-separated text files.\r\n\r\n~~~python\r\n# locate and indicate your file path\r\ndf = pd.read_csv('C:\\...\\order_data.csv')\r\n~~~\r\n\r\n<a id=\"read-excel\"></a>\r\n###### pd.read_excel\r\nFor excel files.\r\n\r\n~~~python\r\n# locate and indicate your file path\r\n# you can also indicate the sheet name if there are more than one\r\ndf = pd.read_csv('C:\\...\\your_file_here.xlsx',\r\n                      sheet_name='sheet_name_here')\r\n~~~\r\n\r\n#### Transforming data\r\nSometimes we only need to perform some basic transformations on our DataFrame and that's where this functions come in handy.\r\n\r\n<a id=\"sort-vals\"></a>\r\n###### df.sort_values\r\nSort DataFrame by the values of chosen column or columns. It is possible to sort twice if you pass more than one column as parameter. You can also choose the direction of your sorting by assigning `ascending` as `True` or `False`.\r\n\r\nSee the [documentation](#https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html).\r\n\r\n~~~python\r\n# sorts in ascending order by the column 'Seller'\r\ndf.sort_values(by='Seller', ascending=True)\r\n~~~\r\n\r\n![Image](../../../../images/post-2/01.png)\r\n\r\n<a id=\"set-index\"></a>\r\n###### df.set_index\r\nSet an existing DataFrame column as the index. You can either use it to replace the original index or to expand it.\r\n\r\nSee the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_index.html).\r\n\r\n~~~python\r\n# using append=True to expand the index\r\n# column 'Seller' is picked\r\ndf.set_index('Seller', append=True)\r\n~~~\r\n\r\n![Image](../../../../images/post-2/02.png)\r\n\r\n<a id=\"reset-idx\"></a>\r\n###### df.reset_index\r\nReset the index of a DataFrame, using the default one instead. Default indexation in python begin with 0. You can either drop the current index or insert it as a column into the DataFrame. \r\n\r\nSee the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reset_index.html)\r\n\r\n~~~python\r\n# drop=False keeps the current index as a column\r\ndf.reset_index(drop=False)\r\n~~~\r\n\r\n![Image](../../../../images/post-2/03.png)\r\n\r\n<a id=\"drop\"></a>\r\n###### df.drop\r\nRemove rows or columns by specifying row index or column name to drop.<br/>\r\nFor `axis=0`, the function searchs through the DataFrame indexes. <br/>\r\nFor `axis=1`, it searchs through its columns.\r\n\r\nSee the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html)\r\n\r\n~~~python\r\n# removes PurchaseDate from the columns\r\ndf.drop('PurchaseDate', axis=1)\r\n~~~\r\n\r\n![Image](../../../../images/post-2/04.png)\r\n\r\n<a id=\"copy\"></a>\r\n###### df.copy\r\nMake a copy of the object's indices and data. If you set `deep=True`, none of the modifications on the original object will reflect on the copy. However, setting `deep=False` makes a shadow copy, and any modification on either the original or the shadow object will reflect on each other.\r\n\r\nSee the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.copy.html)\r\n\r\n~~~python\r\n# creates a copy df\r\n# deep=True is the default parameter\r\ndf_2 = df.copy()\r\nprint(df_2)\r\n~~~\r\n\r\n![Image](../../../../images/post-2/05.png)\r\n\r\n#### Visualizing data\r\n\r\n<a id=\"head\"></a>\r\n###### df.head\r\nReturn the **first** *n* rows. If `n` is not specified, it returns the first 5 rows as default. It is aso possible to return everything except the last *n* rows by passing a negative parameter for `n`.\r\n\r\nSee the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html)\r\n\r\n~~~python\r\n# returns the first 3 rows\r\ndf.head(3)\r\n~~~\r\n\r\n![Image](../../../../images/post-2/06.png)\r\n\r\n<a id=\"tail\"></a>\r\n###### df.tail\r\nReturn the **last** *n* rows. If `n` is not specified, it returns the last 5 rows as default. It is aso possible to return everything except the first *n* rows by passing a negative parameter for `n`.\r\n\r\nSee the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tail.html)\r\n\r\n~~~python\r\n# returns everything except the first 6 rows\r\ndf.tail(-6)\r\n~~~\r\n\r\n![Image](../../../../images/post-2/07.png)\r\n\r\n<a id=\"shape\"></a>\r\n###### df.shape\r\nReturn a tuple representing the dimensionality of the DataFrame. The first element represents the total number of rows, and the second element is the total number of columns.\r\n\r\nSee the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shape.html)\r\n\r\n~~~python\r\n# returns the DataFrame dimensionality\r\ndf.shape\r\n~~~\r\n\r\n![Image](../../../../images/post-2/08.png)\r\n\r\n<a id=\"index\"></a>\r\n###### df.index\r\nReturn the index (row labels) of the DataFrame. If the object index is the default indexation, it will return a RangeIndex object with `start`, `stop`, and `step` parameters.\r\n\r\nSee the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.index.html)\r\n\r\n~~~python\r\n# returns rows labels\r\ndf.index\r\n~~~\r\n\r\n![Image](../../../../images/post-2/09.png)\r\n\r\n<a id=\"cols\"></a>\r\n###### df.columns\r\nReturn a list of the columns labels of the DataFrame.\r\n\r\nSee the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.columns.html)\r\n\r\n~~~python\r\n# returns columns labels\r\ndf.columns\r\n~~~\r\n\r\n![Image](../../../../images/post-2/10.png)\r\n\r\n<a id=\"dtypes\"></a>\r\n###### df.dtypes\r\nIt returns a Series with the data type of each column. If there are columns with mixed types, they'll be stored with the *object* `dtype`.\r\n\r\nSee the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dtypes.html)\r\n\r\n~~~python\r\n# returns the data type of each column\r\ndf.dtypes\r\n~~~\r\n\r\n![Image](../../../../images/post-2/11.png)\r\n\r\n<a id=\"isnull\"></a>\r\n###### df.isnull\r\nUsed to detect missing values. As a reuslt, it returns booleans shaped as the object passed as parameter. \r\n\r\nSee the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.isnull.html)\r\n\r\n~~~python\r\n# detects missing values and returns as booleans\r\ndf.isnull()\r\n~~~\r\n\r\n![Image](../../../../images/post-2/12.png)\r\n\r\n<a id=\"values\"></a>\r\n###### df.values\r\nReturn an array-like representation of the DataFrame. This property takes all the values of the object and returns each row as a list of values stored into a Numpy array.\r\n\r\nSee the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.values.html)\r\n\r\n~~~python\r\n# returns the df values as lists into a numpy array\r\ndf.values\r\n~~~\r\n\r\n![Image](../../../../images/post-2/13.png)\r\n\r\n#### Locating data\r\n\r\n<a id=\"loc\"></a>\r\n###### df.loc\r\nAccess a group of rows and colums by its labels. You can use this property to either access a unique item, an entire row, or any sort of slicing of rows throughout a column or a set of columns passed as input.\r\n\r\nSee the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html) for all the input possibilities.\r\n\r\n~~~python\r\n# access all rows stopping on label 3 of the columns Seller and Item\r\ndf.loc[:3, ['Seller', 'Item']]\r\n~~~\r\n\r\n![Image](../../../../images/post-2/14.png)\r\n\r\n<a id=\"iloc\"></a>\r\n###### df.iloc\r\nIt is an integer position based to locate and access itens of a DataFrame. It returns all the information about a specific row.\r\n\r\nSee the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html)\r\n\r\n~~~python\r\n# selects the indexed row 2 of the DataFrame\r\ndf.iloc[2]\r\n~~~\r\n\r\n![Image](../../../../images/post-2/15.png)\r\n\r\n<a id=\"duplic\"></a>\r\n###### df.duplicated\r\nReturn a boolean Serie pointing the existence of duplicated rows. If no subset of columns is passed, this function will look for duplicated itens considering they are only equal if the entire rows match. You can also set the parameter `keep` as `{'first', 'last', False}` to indicate wheter you want to mark all duplicates except the *first* or *last* one as True, or if you'd like to mark all of them as True.\r\n\r\nSee the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html)\r\n\r\n~~~python\r\n# check if there are duplicated rows when considering Seller and Item only\r\ndf.duplicated(['Seller', 'Item'])\r\n~~~\r\n\r\n![Image](../../../../images/post-2/16.png)\r\n\r\n<a id=\"query\"></a>\r\n###### df.query\r\nQuery the columns of a DataFrame and return where the passed expression is True.\r\n\r\nSee the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.query.html)\r\n\r\n~~~python\r\n# queries all the values and returns where Seller is Carlos \r\ndf.query(\"Seller == 'Carlos'\")\r\n~~~\r\n\r\n![Image](../../../../images/post-2/17.png)\r\n\r\n<a id=\"df-col1\"></a>\r\n###### df['col']\r\nThis is on of the most common and simple ways to locate all the values on a entire column of a DataFrame. All you have to do is passing the columns names into the braces.\r\n\r\n~~~python\r\n# returns all the values into the column UnitPrice\r\ndf['UnitPrice']\r\n~~~\r\n\r\n![Image](../../../../images/post-2/18.png)\r\n\r\n<a id=\"df-col2\"></a>\r\n###### df.your_col\r\nFor a similar result as the previous locating method, you can also call the columns name as it is an attribute of the DataFrame.\r\n\r\n~~~python\r\n# returns all the values into the column UnitPrice\r\ndf.UnitPrice\r\n~~~\r\n\r\n![Image](../../../../images/post-2/18.png)\r\n\r\n#### Summarizing data\r\n\r\n<a id=\"describe\"></a>\r\n###### df.describe\r\nGenerate a decriptive statistics table. It includes measures such as mean, median, range, standard deviation, and more.\r\n\r\nSee the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html)\r\n\r\n~~~python\r\n# descriptive statistics with costumized percentiles\r\ndf.describe(percentiles=[0.2, 0.5, 0.8])\r\n~~~\r\n\r\n![Image](../../../../images/post-2/19.png)\r\n\r\n<a id=\"info\"></a>\r\n###### df.info\r\nPrint a summary of the DataFrame. This summary includes dtypes, columns, and non-null values.\r\n\r\nSee the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html)\r\n\r\n~~~python\r\n# prints summary info\r\ndf.info()\r\n~~~\r\n\r\n![Image](../../../../images/post-2/20.png)\r\n\r\n<a id=\"sum\"></a>\r\n###### df.sum\r\nReturn the sum of the values. You can access a column first to have the results for that specific column.\r\n\r\nSee the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sum.html)\r\n\r\n~~~python\r\n# returns the sum for the column Units\r\ndf.Units.sum()\r\n~~~\r\n\r\n![Image](../../../../images/post-2/21.png)\r\n\r\n<a id=\"count\"></a>\r\n###### df.count\r\nCount the cells with non-NA values for each row or column. NA values here are considered to be any *None*, *NaN*, *NaT* and *numpy.inf* values.\r\n\r\nSee the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.count.html)\r\n\r\n~~~python\r\n# counts non-null cells for each column\r\ndf.count()\r\n~~~\r\n\r\n![Image](../../../../images/post-2/22.png)\r\n\r\n<a id=\"min\"></a>\r\n###### df.min\r\nReturn the minimum of the values over the requested axis. You can either request for the minimum value of some row by passing `axis=0` or pass `axis=1` for the minimum over a column. \r\n\r\nSee the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.min.html)\r\n\r\n~~~python\r\n# minimum values over the columns\r\ndf.min()\r\n~~~\r\n\r\n![Image](../../../../images/post-2/23.png)\r\n\r\n<a id=\"max\"></a>\r\n###### df.max\r\nReturn the maximum of the values over the requested axis.\r\n\r\nSee the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.max.html)\r\n\r\n~~~python\r\n# maximum value over the column UnitPrice\r\ndf.UnitPrice.max()\r\n~~~\r\n\r\n![Image](../../../../images/post-2/24.png)\r\n\r\n<a id=\"mean\"></a>\r\n###### df.mean\r\nReturn the mean of the values over the requested axis.\r\n\r\nSee the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.mean.html)\r\n\r\n~~~python\r\n# mean value over the column UnitPrice\r\ndf.UnitPrice.mean()\r\n~~~\r\n\r\n![Image](../../../../images/post-2/25.png)\r\n\r\n<a id=\"median\"></a>\r\n###### df.median\r\nReturn the median of the values over the requested axis.\r\n\r\nSee the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.mean.html)\r\n\r\n~~~python\r\n# median value over the column UnitPrice \r\ndf.UnitPrice.median()\r\n~~~\r\n\r\n![Image](../../../../images/post-2/26.png)\r\n\r\n<a id=\"corr\"></a>\r\n###### df.corr\r\nCompute pairwise correlations of the DataFrame columns. It's very usefull to understand the correlation between two variables at a glance. A positive correlations indicates that the two variables varies on the same direction, while a negative correlation indicates that the two variables varies on opposite direction. On the other hand, a correlation of 0 indicates no real relationship between the variables.\r\n\r\nSee the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html)\r\n\r\n~~~python\r\n# chacking for existing correlation between numeric variables\r\ndf.corr()\r\n~~~\r\n\r\n![Image](../../../../images/post-2/27.png)\r\n\r\n## Summary\r\nWe covered up many useful functions of the Pandas python package. These are just a lightly demonstration on how this package can be used when working with data. For the intent of this post, the chosen example were pretty simple; but when we are working with large sets of data, or creating machine learning models, they are undoubtedly life savers.\r\n\r\nDon't feel confortable with these simple examples, see the documentation to have a better understanding on everything you are able to do with them, and try if for youself on your own dataset. You'll see how easier it will become once you give it a try and compare the results by yourself!\r\n\r\n---\r\n###### Reference Links:\r\n\r\n[www.codingame.com](https://www.codingame.com/playgrounds/52723/programacao-python-parte-3---prof--marco-vaz/pacote-pandas-dataframe#:~:text=Uma%20S%C3%A9rie%20Pandas%3A%20um%20array,uma%20coluna%20de%20um%20DataFrame)<br/>\r\n[www.pandas.pydata.org](https://pandas.pydata.org/docs/index.html)"},{"__metadata":{"id":"content\\pages\\posts\\the-long-awaited-explanation-that-will-skill-you-on-telling-the-difference-among-ds-ai-ml-and-dl.md","source":"sourcebit-source-filesystem","sourceName":"pages","sourcePath":"content/pages","relSourcePath":"posts\\the-long-awaited-explanation-that-will-skill-you-on-telling-the-difference-among-ds-ai-ml-and-dl.md","relProjectPath":"content\\pages\\posts\\the-long-awaited-explanation-that-will-skill-you-on-telling-the-difference-among-ds-ai-ml-and-dl.md","modelType":"page","modelName":"post","modelLabel":"Post","urlPath":"/posts/the-long-awaited-explanation-that-will-skill-you-on-telling-the-difference-among-ds-ai-ml-and-dl"},"frontmatter":{"title":"The long-awaited explanation that will skill you on telling the difference among DS, AI, ML and DL","subtitle":"Because we all have been hearing a lot about Data Science, Artificial Intelligence, Machine Learning, and Deep Learning lately.","excerpt":"It's not surprising that most of us have already heard something about artificial intelligence at least once in our life, right? Although the first concepts of artificial intelligence were mentioned way before its creation, it is not a so recent research. But many of us still get a little confused when other terminologies begun to appear. So if you have ever felt yourself stuck when trying to tell one from another, stick with me on this post and I'll make it clear as water for you.","date":"2021-04-13","thumb_img_path":"images/post-1/01.jpg","thumb_img_alt":"DS, AI, ML, DL","content_img_path":"images/post-1/01.jpg","seo":{"title":"The long-awaited explanation that will skill you on telling the difference among DS, AI, ML and DL","description":"Because we all have been hearing a lot about Data Science, Artificial Intelligence, Machine Learning, and Deep Learning lately.","extra":[{"name":"og:type","value":"article","keyName":"property"},{"name":"og:title","value":"The long-awaited explanation that will skill you on telling the difference among DS, AI, ML and DL","keyName":"property"},{"name":"og:description","value":"Because we all have been hearing a lot about Data Science, Artificial Intelligence, Machine Learning, and Deep Learning lately.","keyName":"property"},{"name":"og:image","value":"images/post-1/01.jpg","keyName":"property","relativeUrl":true},{"name":"twitter:card","value":"summary_large_image"},{"name":"twitter:title","value":"The long-awaited explanation that will skill you on telling the difference among DS, AI, ML and DL"},{"name":"twitter:description","value":"Because we all have been hearing a lot about Data Science, Artificial Intelligence, Machine Learning, and Deep Learning lately."},{"name":"twitter:image","value":"images/post-1/01.jpg","relativeUrl":true}]},"layout":"post"},"markdown":"\nRaise your hand who haven't ever thought \"What if...\" for the idea of having real intelligent machines among us. Or, still, who haven't ever seen a movie staring human-like robots?\n\nHumans have been fascinated for so long about the idea of having machines performing tasks only we could make, that the first time an Artificial Intelligence (AI) was put into the screen was in 1927. However, it was only during the World War II that we had real studies beginning on this particular field - and that is almost a hundred years from now!\n\nIt was basically because of this urging will to prove that we could create a computer able to think, communicate, and act like a human being, that we now have the ultimate advances we see on our daily life. Smart assistants (like Siri and Alexa), self-driving cars, translators, voice and facial recognizer, disease mapping, plan autopilot, credit card fraud prevention, personalized online marketing, and so many others are all everyday examples of AI been used. But these, what we have, these are way far from be at the finish line.\n\nAs technology earns its own place on the market, researchers raised many other terminologies to support the AI continuous evolution. Machine Learning (ML), Deep Learning (DL), and Data Science (DS) are some of the terms we noticed were added on the AI's toolbox. As they have been mentioned a lot in recent years, it's time for us to understand how they differ from each other, but also how they complete each other.\n\n### Artificial Intelligence\nEverything that make it possible for a machine to present signs of what we call human intelligence can be told as AI. That is, the concepts of AI were created to name all the effort we have been making to make sure that this obsession we have under the question \"Can machines think?\" becomes less and less an unreality.\n\nAI is nothing but our desperate need to prove ourselves that we can create a computer that is not only able to look like a human, but also to act, speak, learn, and think like we do. So it's not only having a cold computer program calculating formulas and giving you the results anymore, it is also having this computer learning from experiences and exhibiting signs of intelligence by itself.\n\nToday, this is still a very abstract concept, since the only type of AI we have is a goal oriented. It means that it is created to be smart at a very specific task, but it doesn't have a proper conscious of what it's been doing.\n\n> A computer would deserve to be called intelligent if it could deceive a human into believing that it was human. <cite>The Turing Test. Alan Turing, 1950</cite>\n\nHowever, studies have been also trying to achieve a more general type of AI, where machines will be able to have its own set of understanding, interpreting, and acting; becoming unpredictable, and indistinguishable from a human being in some given situation.\n\nAlthough this is still not part of our reality, many advances in technology have been substantial for people to start believing that we could, one day, achieve this sort of intelligence. But for now, having computers performing specific tasks and showing, sometimes, better results than a human being... This could be already called madness a few years ago.\n\n### Machine Learning\n![Image](../../../images/post-1/02.png)\n***image*** *by author*\n\nIt was when studies started to get really deeper into discovering how to make machines learn like humans, that the first concept of ML was introduced. In 1959, this field appears as an evolution of the computating learning theory and the pattern recognition studies.\n\n> Machine learning is the field of study that gives computers the ability to learn without being explicitly programmed. <cite>Arthur Samuel, 1959</cite>\n\nScientists no longer wanted to only work on a trial and error system. They wanted to improve their ability to reach out a result that could be acceptably accurate. For that to happen, they saw the need to explore into the real meaning of learning; and so, later on, they come up with this concept that a human learning process could be put into some logic means through an algorithm, and explained to a machine. This machine would be then able to reproduce this \"logic\", they called the \"learning process\", and improve their results by retrieving errors as feedback. This so-fancy concept is nothing but what we already well-know as **learning through experience**.\n\nMany types of learning were developed on later years. But for now, we just need to understand that ML is a study that introduced the idea that we can make machines learn from experience - from data - without actually explicit programming their learning process and behavior.\n\nOnly by explaining the machines how to recognize patterns, researchers created a way to make computers develop a sufficient intelligence to take back their own errors and use them to improve their responses. This is Machine Learning. It is a subfield of AI, since it is the tool used to achieve many of the artificial intelligence applications we can see today. \n\n### Deep Learning\n![Deep Learning Interation](../../../images/post-1/03.png) \n***image*** *by author*\n\nTo be able to make the computer learning theory works with more complex kind of data, and to write the pipeline for the learning process as an algorithm that could interpret things like images or sounds, scientists did an awesome job recreating the human brain engine by simulating our neurons.\n\nI bet that sounds complicated, huh? Let me make it simpler.\n\nIn human beings, neurons are the basic structure responsible for carrying messages to and from our brain. Without them, we wouldn't be able to see, to hear, to feel, to taste, or to walk. It means that our brain needs to be entirely connected to our body in order for us to be able to do whatever thing we might want to do. And this \"connection\" is only possible because we have neurons - and many other structures - to carry electric impulses throughout our body. But machines don't have this connected body we do. So that's where the scientists came up with this insight.\n\n<cite>\"Maybe, we need to simulate a neuron!\"</cite>\n\nFrom that moment, when we found out that our brain worked just like our personal engine, researchers begin to create what they called the **artificial neuron**.\n\nNot all ML algorithms are powerful enough to work with *any* kind of information. Let's think of this in terms of our body. We may say that it's easier for us to understand that if we feel hungry we need to eat, than learning how to read when we still don't know what letters are for.\n\nSimilarly, some ML algorithms only work when the information we provide them are very organized and structured, just like our body is organized to know that eating is the natural action for when we feel hungry. This *little* issue brought up scientists the discussion about how to make machines understand data that are not so organized and structured, like images and audio files.\n\nThe artificial neurons were definitely a huge leap to the ML algorithms evolution. They are the concept of Deep Learning as it is.\n\nDL is a class of ML algorithms that use concepts way more complex, including multiple layers of data processing, to extract features from unorganized and non-structured data, that is, raw data. In other words, DL can be seen as an evolutionary complement of the ML algorithms, that has been used to bring us even closer to the initial idea of having general artificial intelligence created. Now, with the advances of DL algorithms, we can not only learn from basic set of data, but also break very complex data into small levels, and work with these smaller information into layers that will, at the end, bring all the processing together to come up with final features.\n\nBut you might be asking yourself <cite>\"Where does this Data Science thing go?\"</cite>\n\n### Data Science\nNow that we have all these technologies being created, it's time for us to think about its usability for good. And if you just though of DS as one of the ways to take advantage of these tools, you get it right, pal!\n\nData Science is an interdisciplinary field that involves a wide range of subjects, such as mathematics, statistics, computing processes, algorithms, business understanding, data analysis, and so on. The main goal of a *data scientist* is to extract valuable knowledge from information - called *data* -, in order to provide actionable insights in a broad range of application domain.\n\nTo be even clearer, DS is a field that can make use of the ML and DL concepts and tools to come up with insights that will turn into solutions for you.\n\nBut who might be *you*?\n\nYou could be anyone who need to solve a problem and who have a set of information, but still don't have a clue on how to use it. A data scientist will take her or his ability to work on big sets of data to manipulate, organize, and interpret them, and finally provide you with a clean image of what you need to turn your decision making process easier.\n\n### Summary\n![Image](../../../images/post-1/04.png)\n***image*** *by author*\n\nAnd to put all these information into one place, here is a final picture of the relationship among all these terminologies.\n\nBriefly, AI can be said as everything and every effort that make it possible for a machine to present signs of what we call human intelligence. Also, ML is a tool that we presented for the AI that allowed machines to learn by being exposed to external information. This way, we can understand that ML is part of the AI world.\n\nDigging a little bit deeper, we have DL that came as a complement to the ML algorithms to solve some restrictions when working with more complex type of data. That said, we can understand that DL is part of ML, being considered as a subclass within the whole package of ML algorithms.\n\nFinally, DS is well-known as a field of study that is able to take advantage of all of these tools, and combine them along with some mathematical, statistical, and analytical knowledge to extract valuable information for the most varied domains. \n\n---\n**Here you can have some more valuable information:** <br/>\n[Toward Data Science](https://towardsdatascience.com/understanding-the-difference-between-ai-ml-and-dl-cceb63252a6c)   (EN) <br/>\n[A Hist칩ria da Intelig칡ncia Artificial](https://www.youtube.com/watch?v=Lhu8bdmkMCM) (PT-BR)\n"},{"__metadata":{"id":"content\\pages\\success.md","source":"sourcebit-source-filesystem","sourceName":"pages","sourcePath":"content/pages","relSourcePath":"success.md","relProjectPath":"content\\pages\\success.md","modelType":"page","modelName":"page","modelLabel":"Page","urlPath":"/success"},"frontmatter":{"title":"Thank You!","layout":"page"},"markdown":"\nThank you for contacting me! I will get back in touch with you soon.\n\n**Have a great day!**\n"},{"__metadata":{"id":"content\\pages\\todo-posts\\data-science-acronyms-cheatsheet.md","source":"sourcebit-source-filesystem","sourceName":"pages","sourcePath":"content/pages","relSourcePath":"todo-posts\\data-science-acronyms-cheatsheet.md","relProjectPath":"content\\pages\\todo-posts\\data-science-acronyms-cheatsheet.md","modelType":"page","modelName":"page","modelLabel":"Page","urlPath":"/todo-posts/data-science-acronyms-cheatsheet"},"frontmatter":{"title":"Data Science acronyms cheatsheet.","date":"2021-04-05","tags":"java,spring boot,logging"},"markdown":""},{"__metadata":{"id":"content\\pages\\todo-posts\\http-status-codes.md","source":"sourcebit-source-filesystem","sourceName":"pages","sourcePath":"content/pages","relSourcePath":"todo-posts\\http-status-codes.md","relProjectPath":"content\\pages\\todo-posts\\http-status-codes.md","modelType":"page","modelName":"page","modelLabel":"Page","urlPath":"/todo-posts/http-status-codes"},"frontmatter":{"title":"Main HTTP Status Codes for you to Favorite","date":"yyyy-mm-dd","tags":"java,spring boot,logging"},"markdown":""},{"__metadata":{"id":"content\\pages\\todo-posts\\what-is-an-API.md","source":"sourcebit-source-filesystem","sourceName":"pages","sourcePath":"content/pages","relSourcePath":"todo-posts\\what-is-an-API.md","relProjectPath":"content\\pages\\todo-posts\\what-is-an-API.md","modelType":"page","modelName":"page","modelLabel":"Page","urlPath":"/todo-posts/what-is-an-api"},"frontmatter":{"title":"What in earth is an API?","date":"yyyy-mm-dd","tags":"java,spring boot,logging"},"markdown":""}],"data":{"__metadata":{"id":"sourcebit-source-filesystem:data","source":"sourcebit-source-filesystem"},"config":{"__metadata":{"id":"content\\data\\config.json","source":"sourcebit-source-filesystem","sourceName":"data","sourcePath":"content/data","relSourcePath":"config.json","relProjectPath":"content\\data\\config.json","modelType":"data","modelName":"config","modelLabel":"Site Configuration"},"title":"Stackbit Fjord Theme","path_prefix":"/","palette":"yellow","header":{"title":"Fjord","tagline":"Data Scientist","logo_img":"images/logo.svg","logo_img_alt":"Fjord Logo","background_img":"images/header-bg.JPG","has_nav":true,"nav_links":[{"label":"Home","url":"/","style":"link","__metadata":{"modelType":"object","modelName":"action","modelLabel":"Action"}},{"label":"About","url":"/about","style":"link","__metadata":{"modelType":"object","modelName":"action","modelLabel":"Action"}},{"label":"Portfolio","url":"/portfolio","style":"link","__metadata":{"modelType":"object","modelName":"action","modelLabel":"Action"}},{"label":"Contact","url":"/contact","style":"link","__metadata":{"modelType":"object","modelName":"action","modelLabel":"Action"}}],"has_social":true,"social_links":[{"label":"Twitter","url":"https://twitter.com/","style":"icon","icon_class":"twitter","new_window":true,"__metadata":{"modelType":"object","modelName":"action","modelLabel":"Action"}},{"label":"Instagram","url":"https://www.instagram.com/","style":"icon","icon_class":"instagram","new_window":true,"__metadata":{"modelType":"object","modelName":"action","modelLabel":"Action"}},{"label":"GitHub","url":"https://github.com/quelcamara","style":"icon","icon_class":"github","new_window":true,"__metadata":{"modelType":"object","modelName":"action","modelLabel":"Action"}},{"label":"LinkedIn","url":"https://www.linkedin.com/in/raquel-camara","style":"icon","icon_class":"linkedin","new_window":true,"__metadata":{"modelType":"object","modelName":"action","modelLabel":"Action"}},{"label":"DEV","url":"https://dev.to/","style":"icon","icon_class":"dev","new_window":true,"__metadata":{"modelType":"object","modelName":"action","modelLabel":"Action"}}],"__metadata":{"modelType":"object","modelName":"header","modelLabel":"Header Configuration"}},"footer":{"content":"&copy; Stackbit. All rights reserved. This Jamstack site was created with <a href=\"https://www.stackbit.com/?utm_source=deployed-footer\" target=\"_blank\" rel=\"noopener\">Stackbit</a>. Create yours <a href=\"https://app.stackbit.com/create?theme=fjord&utm_source=deployed-footer\" target=\"_blank\" rel=\"noopener\">now</a>","__metadata":{"modelType":"object","modelName":"footer","modelLabel":"Footer Configuration"}},"domain":"https://green-artichoke-e3ccb.netlify.app"}},"liveUpdate":true,"liveUpdatePort":8088,"liveUpdateEventName":"props_changed"},"pages":[{"path":"/","page":{"__metadata":{"id":"content\\pages\\index.md","source":"sourcebit-source-filesystem","sourceName":"pages","sourcePath":"content/pages","relSourcePath":"index.md","relProjectPath":"content\\pages\\index.md","modelType":"page","modelName":"home","modelLabel":"Home","urlPath":"/"},"frontmatter":{"title":"Home","has_more_link":true,"more_link_text":"Keep reading","seo":{"title":"Raquel C칙mara - Data Scientist","description":"A Data Scientist Diary","extra":[{"name":"og:type","value":"website","keyName":"property"},{"name":"og:title","value":"Stackbit Fjord Theme","keyName":"property"},{"name":"og:description","value":"A Data Scientist Diary","keyName":"property"},{"name":"og:image","value":"images/home.jpg","keyName":"property","relativeUrl":true},{"name":"twitter:card","value":"summary_large_image"},{"name":"twitter:title","value":"Stackbit Fjord Theme"},{"name":"twitter:description","value":"A Data Scientist Diary"},{"name":"twitter:image","value":"images/home.jpg","relativeUrl":true}]},"layout":"home"},"markdown":""}},{"path":"/contact","page":{"__metadata":{"id":"content\\pages\\contact.md","source":"sourcebit-source-filesystem","sourceName":"pages","sourcePath":"content/pages","relSourcePath":"contact.md","relProjectPath":"content\\pages\\contact.md","modelType":"page","modelName":"contact","modelLabel":"Contact","urlPath":"/contact"},"frontmatter":{"title":"Get in Touch","img_path":"images/contact.jpg","form_id":"contactForm","form_action":"/success","form_fields":[{"input_type":"text","name":"name","label":"Name","default_value":"Your name","is_required":true},{"input_type":"email","name":"email","label":"Email","default_value":"Your email address","is_required":true},{"input_type":"select","name":"subject","label":"Subject","default_value":"Please select","options":["Get in touch","Post suggestions","Partnership","Error on the site","Other"]},{"input_type":"textarea","name":"message","label":"Message","default_value":"Your message"},{"input_type":"checkbox","name":"consent","label":"I understand that this form is storing my submitted information so I can be contacted."}],"submit_label":"Send Message","seo":{"title":"Get in Touch","description":"This is the contact page","extra":[{"name":"og:type","value":"website","keyName":"property"},{"name":"og:title","value":"Get in Touch","keyName":"property"},{"name":"og:description","value":"This is the contact page","keyName":"property"},{"name":"og:image","value":"images/contact.jpg","keyName":"property","relativeUrl":true},{"name":"twitter:card","value":"summary_large_image"},{"name":"twitter:title","value":"Get in Touch"},{"name":"twitter:description","value":"This is the contact page"},{"name":"twitter:image","value":"images/contact.jpg","relativeUrl":true}]},"layout":"contact"},"markdown":"\nTo get in touch fill the form below.\n"}},{"path":"/about","page":{"__metadata":{"id":"content\\pages\\about.md","source":"sourcebit-source-filesystem","sourceName":"pages","sourcePath":"content/pages","relSourcePath":"about.md","relProjectPath":"content\\pages\\about.md","modelType":"page","modelName":"page","modelLabel":"Page","urlPath":"/about"},"frontmatter":{"title":"About Me","subtitle":"I am so glad to have you here!","img_path":"images/about.jpg","seo":{"title":"About Me","description":"A page about me and my work","extra":[{"name":"og:type","value":"website","keyName":"property"},{"name":"og:title","value":"About Me","keyName":"property"},{"name":"og:description","value":"A page about me and my work","keyName":"property"},{"name":"og:image","value":"images/about.jpg","keyName":"property","relativeUrl":true},{"name":"twitter:card","value":"summary_large_image"},{"name":"twitter:title","value":"About Me"},{"name":"twitter:description","value":"A page about me and my work"},{"name":"twitter:image","value":"images/about.jpg","relativeUrl":true}]},"layout":"page"},"markdown":"\nWelcome to the most beginner-friendly blog on **Data Science** you will ever see! Hope you are ready to go into the hotter topics on **Data Analysis**, **Machine Learning**, **Artificial Inteligence**, and so many other exciting stuff about technology and programming without getting all chaotic about those hard and complex book definitions.\n\nSo let us not take it too long!</br>\nBut first, let me introduce myself properly.\n\nI am a former Designer and Civil Engineer who ended up falling in love with Data Science after a long time struggling to decide if I should keep on following the path I had once begun, or if I should just throw it all away and follow my heart into something I could finally see myself in. I know it might sound a little cheesy at some point, but that's what it is.  \n\nI am a very curious person, and when I first dumped into Data Science, it was such a completely new world for me that I found myself unbearable amazed by the so many things I felt I just *needed* to know right away.\n\n>Any sufficiently advanced technology is indistinguishable from magic. <cite>Arthur C. Clarke</cite>\n\n So here we are!\n\nWhen I decided I wanted to keep track of my progress I found that building a blog would be just the perfect beginning. That's because here I can not only keep my records about the things I am most recently studying, but I can also improve some communication skills, and - last but not least! - maybe I am able to help other people, in the near future, who are also starting their jorney into Data Science.\n\nNo changing of career is easy as it seems. It demands a lot of effort and resilience from you to start all over again. And that's why I am here! I hope this blog finds you in a perfect timing so you don't give up on following the path you've been dreaming.\n\n*Be very welcome and enjoy your stay!* 游눹\n"}},{"path":"/portfolio","page":{"__metadata":{"id":"content\\pages\\portfolio.md","source":"sourcebit-source-filesystem","sourceName":"pages","sourcePath":"content/pages","relSourcePath":"portfolio.md","relProjectPath":"content\\pages\\portfolio.md","modelType":"page","modelName":"page","modelLabel":"Page","urlPath":"/portfolio"},"frontmatter":{"title":"Portfolio","subtitle":"Topic under construction.","img_path":"images/portfolio.jpg","seo":{"title":"Portfolio","description":"My data science portfolio","extra":[{"name":"og:type","value":"website","keyName":"property"},{"name":"og:title","value":"Portfolio","keyName":"property"},{"name":"og:description","value":"My data science portfolio","keyName":"property"},{"name":"og:image","value":"images/portfolio.jpg","keyName":"property","relativeUrl":true},{"name":"twitter:card","value":"summary_large_image"},{"name":"twitter:title","value":"Portfolio"},{"name":"twitter:description","value":"My data science portfolio"},{"name":"twitter:image","value":"images/portfolio.jpg","relativeUrl":true}]},"layout":"page"},"markdown":""}},{"path":"/success","page":{"__metadata":{"id":"content\\pages\\success.md","source":"sourcebit-source-filesystem","sourceName":"pages","sourcePath":"content/pages","relSourcePath":"success.md","relProjectPath":"content\\pages\\success.md","modelType":"page","modelName":"page","modelLabel":"Page","urlPath":"/success"},"frontmatter":{"title":"Thank You!","layout":"page"},"markdown":"\nThank you for contacting me! I will get back in touch with you soon.\n\n**Have a great day!**\n"}},{"path":"/todo-posts/data-science-acronyms-cheatsheet","page":{"__metadata":{"id":"content\\pages\\todo-posts\\data-science-acronyms-cheatsheet.md","source":"sourcebit-source-filesystem","sourceName":"pages","sourcePath":"content/pages","relSourcePath":"todo-posts\\data-science-acronyms-cheatsheet.md","relProjectPath":"content\\pages\\todo-posts\\data-science-acronyms-cheatsheet.md","modelType":"page","modelName":"page","modelLabel":"Page","urlPath":"/todo-posts/data-science-acronyms-cheatsheet"},"frontmatter":{"title":"Data Science acronyms cheatsheet.","date":"2021-04-05","tags":"java,spring boot,logging"},"markdown":""}},{"path":"/todo-posts/http-status-codes","page":{"__metadata":{"id":"content\\pages\\todo-posts\\http-status-codes.md","source":"sourcebit-source-filesystem","sourceName":"pages","sourcePath":"content/pages","relSourcePath":"todo-posts\\http-status-codes.md","relProjectPath":"content\\pages\\todo-posts\\http-status-codes.md","modelType":"page","modelName":"page","modelLabel":"Page","urlPath":"/todo-posts/http-status-codes"},"frontmatter":{"title":"Main HTTP Status Codes for you to Favorite","date":"yyyy-mm-dd","tags":"java,spring boot,logging"},"markdown":""}},{"path":"/todo-posts/what-is-an-api","page":{"__metadata":{"id":"content\\pages\\todo-posts\\what-is-an-API.md","source":"sourcebit-source-filesystem","sourceName":"pages","sourcePath":"content/pages","relSourcePath":"todo-posts\\what-is-an-API.md","relProjectPath":"content\\pages\\todo-posts\\what-is-an-API.md","modelType":"page","modelName":"page","modelLabel":"Page","urlPath":"/todo-posts/what-is-an-api"},"frontmatter":{"title":"What in earth is an API?","date":"yyyy-mm-dd","tags":"java,spring boot,logging"},"markdown":""}},{"path":"/posts/3-mighty-libraries-for-a-data-science-beginner-to-become-friends-with-part-1","page":{"__metadata":{"id":"content\\pages\\posts\\3-mighty-libraries-for-a-data-science-beginner-to-become-friends-with-part-1.md","source":"sourcebit-source-filesystem","sourceName":"pages","sourcePath":"content/pages","relSourcePath":"posts\\3-mighty-libraries-for-a-data-science-beginner-to-become-friends-with-part-1.md","relProjectPath":"content\\pages\\posts\\3-mighty-libraries-for-a-data-science-beginner-to-become-friends-with-part-1.md","modelType":"page","modelName":"post","modelLabel":"Post","urlPath":"/posts/3-mighty-libraries-for-a-data-science-beginner-to-become-friends-with-part-1"},"frontmatter":{"title":"3 mighty libraries for a Data Science beginner to become friends with (part 1)","subtitle":"I will tell you the secret for this friendship to work, and why you should stick with them forever.","excerpt":"It is very common to get confused about what we should learn at the very beginning of our studies. But no need to start yelling at a cat! I am sure that after these posts you will be gifted with plenty of working for the next few days. On this first section out of three posts, we'll discover the strength of Pandas.","date":"2021-04-23","thumb_img_path":"images/post-2/cover.jpg","thumb_img_alt":"migthy libraries","content_img_path":"images/post-2/cover.jpg","seo":{"title":"3 mighty libraries for a Data Science beginner to become friends with (part 1)","description":"I will tell you the secret for this friendship to work, and why you should stick with them forever.","extra":[{"name":"og:type","value":"article","keyName":"property"},{"name":"og:title","value":"3 mighty libraries for a Data Science beginner to become friends with (part 1)","keyName":"property"},{"name":"og:description","value":"I will tell you the secret for this friendship to work, and why you should stick with them forever.","keyName":"property"},{"name":"og:image","value":"images/post-2/cover.jpg","keyName":"property","relativeUrl":true},{"name":"twitter:card","value":"summary_large_image"},{"name":"twitter:title","value":"3 mighty libraries for a Data Science beginner to become friends with (part 1)"},{"name":"twitter:description","value":"I will tell you the secret for this friendship to work, and why you should stick with them forever."},{"name":"twitter:image","value":"images/post-2/cover.jpg","relativeUrl":true}]},"layout":"post"},"markdown":"\r\nI understand you.\r\n\r\nWhen we start something new, we use to get so excited that we begin to google search a lot of random stuff about that thing. And it becomes almost inevitable not to get lost on the endless sea of information available on the internet. But by putting some effort, we are able to filter what is important to know based on our current level.\r\n\r\nOn this set of posts, you will be given precious information about three **python** libraries that you should definitely look up:\r\n\r\n- Pandas\r\n- NumPy\r\n- Matplotlib\r\n\r\nYou probably already heard a thing or two about any of these. But if you didn't pay attention before - because maybe you thought they were not worth it - this is your chance to redeem yourself.\r\n\r\nTo better illustrate the next topics, consider the following dataset for demonstration purposes:\r\n\r\n&nbsp; | PurchaseDate |   Region  |   State   | Seller |  Item   | Units | UnitPrice  \r\n:-----:| :-----------:| :--------:| :--------:| :-----:| :------:| :----:| :-------:\r\n   0   | 10-Jun-2020  | Northeast |   Bahia   | Tobias | Stove   |  62   |  400.99\r\n   1   | 11-Jun-2020  | Southeast | S칚o Paulo | Nadia  | Fridge  |  29   |  100.99\r\n   2   |  3-Aug-2020  | Northeast |   Cear치   | Carlos | Stove   |  55   | 1200.49\r\n   3   | 22-Aug-2020  | Northeast |   Bahia   | Pedro  | Fridge  |  81   | 1900.99\r\n   4   | 26-Aug-2020  |  Midwest  |   Goi치s   | Tania  | Blender |  42   | 2300.95\r\n   5   | 10-Sep-2020  | Northeast |  Sergipe  | Tobias | Carpet  |  35   |  400.99\r\n   6   | 12-Sep-2020  |   North   |   Par치    | Carlos | Carpet  |   3   | 2750.00\r\n   7   |  7-Oct-2020  | Northeast |  Sergipe  | Nadia  | Blender |   2   | 1250.00\r\n   8   | 15-Oct-2020  |   North   | Amazonas  | Pedro  | Stove   |   7   | 1000.29\r\n   9   | 27-Nov-2020  | Southeast | S칚o Paulo | Nadia  | Fridge  |  16   | 1500.99\r\n  10   | 13-Dec-2020  |   South   |  Paran치   | Tania  | Blender |  76   | 1450.99\r\n\r\n***file:*** order_data.csv\r\n\r\nOn this first post, we'll start with **Pandas**. And if you want to check on some specific functionality, I will leave you the table below so you can also go straight to the point.\r\n\r\n|    Load and Transform     |     Visualize     |           Locate           |       Summarize       |  \r\n:-------------------------: | :---------------: | :------------------------: | :-------------------: | \r\n[read_csv](#read-csv)       | [head](#head)     | [loc](#loc)                | [describe](#describe) |\r\n[read_excel](#read-excel)   | [tail](#tail)     | [iloc](#iloc)              | [info](#info)         |\r\n[sort_values](#sort-vals)   | [shape](#shape)   | [duplicated](#duplic)      | [sum](#sum)           |\r\n[set_index](#set-index)     | [index](#index)   | [query](#query)            | [count](#count)       |\r\n[reset_index](#reset-idx)   | [columns](#cols)  | [df['col']](#df-col1)      | [min](#min)           |\r\n[drop](#drop)               | [dtypes](#dtypes) | [df.your_col](#df-col2)    | [max](#max)           |\r\n[copy](#copy)               | [isnull](#isnull) |          ---               | [mean](#mean)         |\r\n---                         | [values](#values) |          ---               | [median](#median)     |\r\n---                         |        ---        |          ---               | [corr](#corr)         |\r\n\r\n\r\n## Pandas\r\n![Panda](../../images/post-2/01-panda.jpg)\r\n***image*** by [Eric Baccega](https://onebigphoto.com/giant-panda-sleeping-on-a-tree-china/)\r\n\r\nPandas is a very powerful python library widely used by data scientists and/or analysts for both manipulating and analysing data. It also works well with many other python modules, and its main advantage is having  an intuitive and practical usability without compromising its functionality.\r\n\r\nFor convenience, pandas use to be loaded into the project with the allias `pd`, as shown below:\r\n\r\n~~~python\r\nimport pandas as pd\r\n\r\n~~~\r\n\r\nIt is useful so we can just use this short allias instead of typing the whole package name every time we want to use a pandas function. This library also allows us to create two type of structures that make the manipulating easier: **Series** and **Dataframes**.\r\n\r\n#### Series\r\nAccording to pandas official [documentation](https://pandas.pydata.org/docs/index.html), a series is a one-dimensional ndarray (an array that belongs to the NumPy class `ndarray`) with axis labels.\r\n\r\n*Omg, this...*\r\n\r\nBetter saying, a pandas series is nothing but an unidimensional array (having a unique dimension) which can store any sort of data with labels or indexes as the axis. In short, it is like a column of a dataframe. Let's see how to create a series in pandas and how to identify its structure. The following code can be replicated in your jupyter notebook:\r\n\r\n~~~python\r\n# imports\r\nIn [1]: import pandas as pd\r\n\r\n# creates a series to store people names\r\nIn [2]: names = pd.Series(['Carlos', 'Sara', 'Louise', 'James'])\r\n\r\nIn [3]: names\r\nOut[3]: 0   Carlos\r\n        1     Sara\r\n        2   Louise\r\n        3    James\r\n        dtype: object\r\n\r\n~~~\r\n\r\nNote that, as indexation in python begins with 0, the index range of the series created goes from 0 to `n-1`, where *n* is the number of elements on your series. This is a very important thing to remember, and which might cause a lot of malfunctioning on your codes if you mess that up.\r\n\r\nWe can also see that, as I haven't specified any index range for my series, pandas automaticatly insert the standard indexation. However, if I want a different label for my axis, I can specify that when creating the object. See how it looks:\r\n\r\n~~~python\r\n# creates a series to store animals species\r\nIn [2]: animals = pd.Series(['Dog', 'Elephant', 'Fox', 'Eagle'],\r\n                            index=['A', 'B', 'C', 'D'])\r\n\r\nIn [3]: animals\r\nOut[3]: A        Dog\r\n        B   Elephant\r\n        C        Fox\r\n        D      Eagle\r\n        dtype: object\r\n\r\n~~~\r\n\r\nThese are, in fact, very simple examples. But they might help you having an ideia of what a series look like.\r\n\r\n#### Dataframes\r\nDifferently from a series, a pandas dataframe is a two-dimensional tabular structure where data is labeled by its own combination of column and row. This structure is size-mutable and potentially heterogeneous. That is, we can easily create a dataframe with two columns and two rows, and then add new columns and rows for this same object. And we can store different types of data on the same dataframe, which can be very convinient in many situations.\r\n\r\nLet's see how it works on the jupyter notebook:\r\n\r\n~~~python\r\n# imports\r\nIn [1]: import pandas as pd\r\n\r\n# creates a dataframe to store people names, ages, and heights\r\nIn [2]: names = pd.DataFrame([['Carlos', 27, 1.78], ['Sara', 12, 1.35],\r\n                              ['Louise', 35, 1.62], ['James', 18, 1.87]],\r\n                              columns=['name', 'age', 'height'],\r\n                              index=['i', 'ii','iii', 'iv'])\r\n\r\nIn [3]: names\r\nOut[3]:      name   age   height\r\n        i  Carlos    27     1.78\r\n       ii    Sara    12     1.35\r\n      iii  Louise    35     1.62\r\n       iv   James    18     1.87\r\n~~~\r\n\r\nCould you notice how they differ? Now we have a table storing a set of information that we can either access by the index - returning all the information in a the row - or by the combination of index and columns - returning a single desired value.\r\n\r\nAnd if we just want to go on regular indexing, we only need to remove the `index` attribute from the function.\r\n\r\nSee the official [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) for more information.\r\n\r\nJust so to remind you, all the operations from now on will take into consideration the dataset we defiined on the very beginning of this post. Also, see that you will face many abbreviations and acronyms on your way through the data science world. I will provide you a cheatsheet on later posts. \r\n\r\nNow, let us finally see what pandas can bring us!\r\n\r\n#### Loading data\r\nPandas has many functions to load data into your project. You can mine data from a csv - a text file - or an excel spreadsheet, for instance. But it is also possible to get information from SQL and HTML tables, SQL query, JSON strings, Google BigQuery, Stata .dta files, and so on. See [here](https://pandas.pydata.org/docs/reference/io.html) all the options pandas offers.\r\n\r\nHere are two frequently used functions:\r\n\r\n<a id=\"read-csv\"></a>\r\n###### pd.read_csv\r\nFor comma-separated text files.\r\n\r\n~~~python\r\n# locate and indicate your file path\r\ndf = pd.read_csv('C:\\...\\order_data.csv')\r\n~~~\r\n\r\n<a id=\"read-excel\"></a>\r\n###### pd.read_excel\r\nFor excel files.\r\n\r\n~~~python\r\n# locate and indicate your file path\r\n# you can also indicate the sheet name if there are more than one\r\ndf = pd.read_csv('C:\\...\\your_file_here.xlsx',\r\n                      sheet_name='sheet_name_here')\r\n~~~\r\n\r\n#### Transforming data\r\nSometimes we only need to perform some basic transformations on our DataFrame and that's where this functions come in handy.\r\n\r\n<a id=\"sort-vals\"></a>\r\n###### df.sort_values\r\nSort DataFrame by the values of chosen column or columns. It is possible to sort twice if you pass more than one column as parameter. You can also choose the direction of your sorting by assigning `ascending` as `True` or `False`.\r\n\r\nSee the [documentation](#https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html).\r\n\r\n~~~python\r\n# sorts in ascending order by the column 'Seller'\r\ndf.sort_values(by='Seller', ascending=True)\r\n~~~\r\n\r\n![Image](../../../../images/post-2/01.png)\r\n\r\n<a id=\"set-index\"></a>\r\n###### df.set_index\r\nSet an existing DataFrame column as the index. You can either use it to replace the original index or to expand it.\r\n\r\nSee the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_index.html).\r\n\r\n~~~python\r\n# using append=True to expand the index\r\n# column 'Seller' is picked\r\ndf.set_index('Seller', append=True)\r\n~~~\r\n\r\n![Image](../../../../images/post-2/02.png)\r\n\r\n<a id=\"reset-idx\"></a>\r\n###### df.reset_index\r\nReset the index of a DataFrame, using the default one instead. Default indexation in python begin with 0. You can either drop the current index or insert it as a column into the DataFrame. \r\n\r\nSee the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reset_index.html)\r\n\r\n~~~python\r\n# drop=False keeps the current index as a column\r\ndf.reset_index(drop=False)\r\n~~~\r\n\r\n![Image](../../../../images/post-2/03.png)\r\n\r\n<a id=\"drop\"></a>\r\n###### df.drop\r\nRemove rows or columns by specifying row index or column name to drop.<br/>\r\nFor `axis=0`, the function searchs through the DataFrame indexes. <br/>\r\nFor `axis=1`, it searchs through its columns.\r\n\r\nSee the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html)\r\n\r\n~~~python\r\n# removes PurchaseDate from the columns\r\ndf.drop('PurchaseDate', axis=1)\r\n~~~\r\n\r\n![Image](../../../../images/post-2/04.png)\r\n\r\n<a id=\"copy\"></a>\r\n###### df.copy\r\nMake a copy of the object's indices and data. If you set `deep=True`, none of the modifications on the original object will reflect on the copy. However, setting `deep=False` makes a shadow copy, and any modification on either the original or the shadow object will reflect on each other.\r\n\r\nSee the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.copy.html)\r\n\r\n~~~python\r\n# creates a copy df\r\n# deep=True is the default parameter\r\ndf_2 = df.copy()\r\nprint(df_2)\r\n~~~\r\n\r\n![Image](../../../../images/post-2/05.png)\r\n\r\n#### Visualizing data\r\n\r\n<a id=\"head\"></a>\r\n###### df.head\r\nReturn the **first** *n* rows. If `n` is not specified, it returns the first 5 rows as default. It is aso possible to return everything except the last *n* rows by passing a negative parameter for `n`.\r\n\r\nSee the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html)\r\n\r\n~~~python\r\n# returns the first 3 rows\r\ndf.head(3)\r\n~~~\r\n\r\n![Image](../../../../images/post-2/06.png)\r\n\r\n<a id=\"tail\"></a>\r\n###### df.tail\r\nReturn the **last** *n* rows. If `n` is not specified, it returns the last 5 rows as default. It is aso possible to return everything except the first *n* rows by passing a negative parameter for `n`.\r\n\r\nSee the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tail.html)\r\n\r\n~~~python\r\n# returns everything except the first 6 rows\r\ndf.tail(-6)\r\n~~~\r\n\r\n![Image](../../../../images/post-2/07.png)\r\n\r\n<a id=\"shape\"></a>\r\n###### df.shape\r\nReturn a tuple representing the dimensionality of the DataFrame. The first element represents the total number of rows, and the second element is the total number of columns.\r\n\r\nSee the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shape.html)\r\n\r\n~~~python\r\n# returns the DataFrame dimensionality\r\ndf.shape\r\n~~~\r\n\r\n![Image](../../../../images/post-2/08.png)\r\n\r\n<a id=\"index\"></a>\r\n###### df.index\r\nReturn the index (row labels) of the DataFrame. If the object index is the default indexation, it will return a RangeIndex object with `start`, `stop`, and `step` parameters.\r\n\r\nSee the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.index.html)\r\n\r\n~~~python\r\n# returns rows labels\r\ndf.index\r\n~~~\r\n\r\n![Image](../../../../images/post-2/09.png)\r\n\r\n<a id=\"cols\"></a>\r\n###### df.columns\r\nReturn a list of the columns labels of the DataFrame.\r\n\r\nSee the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.columns.html)\r\n\r\n~~~python\r\n# returns columns labels\r\ndf.columns\r\n~~~\r\n\r\n![Image](../../../../images/post-2/10.png)\r\n\r\n<a id=\"dtypes\"></a>\r\n###### df.dtypes\r\nIt returns a Series with the data type of each column. If there are columns with mixed types, they'll be stored with the *object* `dtype`.\r\n\r\nSee the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dtypes.html)\r\n\r\n~~~python\r\n# returns the data type of each column\r\ndf.dtypes\r\n~~~\r\n\r\n![Image](../../../../images/post-2/11.png)\r\n\r\n<a id=\"isnull\"></a>\r\n###### df.isnull\r\nUsed to detect missing values. As a reuslt, it returns booleans shaped as the object passed as parameter. \r\n\r\nSee the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.isnull.html)\r\n\r\n~~~python\r\n# detects missing values and returns as booleans\r\ndf.isnull()\r\n~~~\r\n\r\n![Image](../../../../images/post-2/12.png)\r\n\r\n<a id=\"values\"></a>\r\n###### df.values\r\nReturn an array-like representation of the DataFrame. This property takes all the values of the object and returns each row as a list of values stored into a Numpy array.\r\n\r\nSee the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.values.html)\r\n\r\n~~~python\r\n# returns the df values as lists into a numpy array\r\ndf.values\r\n~~~\r\n\r\n![Image](../../../../images/post-2/13.png)\r\n\r\n#### Locating data\r\n\r\n<a id=\"loc\"></a>\r\n###### df.loc\r\nAccess a group of rows and colums by its labels. You can use this property to either access a unique item, an entire row, or any sort of slicing of rows throughout a column or a set of columns passed as input.\r\n\r\nSee the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html) for all the input possibilities.\r\n\r\n~~~python\r\n# access all rows stopping on label 3 of the columns Seller and Item\r\ndf.loc[:3, ['Seller', 'Item']]\r\n~~~\r\n\r\n![Image](../../../../images/post-2/14.png)\r\n\r\n<a id=\"iloc\"></a>\r\n###### df.iloc\r\nIt is an integer position based to locate and access itens of a DataFrame. It returns all the information about a specific row.\r\n\r\nSee the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html)\r\n\r\n~~~python\r\n# selects the indexed row 2 of the DataFrame\r\ndf.iloc[2]\r\n~~~\r\n\r\n![Image](../../../../images/post-2/15.png)\r\n\r\n<a id=\"duplic\"></a>\r\n###### df.duplicated\r\nReturn a boolean Serie pointing the existence of duplicated rows. If no subset of columns is passed, this function will look for duplicated itens considering they are only equal if the entire rows match. You can also set the parameter `keep` as `{'first', 'last', False}` to indicate wheter you want to mark all duplicates except the *first* or *last* one as True, or if you'd like to mark all of them as True.\r\n\r\nSee the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html)\r\n\r\n~~~python\r\n# check if there are duplicated rows when considering Seller and Item only\r\ndf.duplicated(['Seller', 'Item'])\r\n~~~\r\n\r\n![Image](../../../../images/post-2/16.png)\r\n\r\n<a id=\"query\"></a>\r\n###### df.query\r\nQuery the columns of a DataFrame and return where the passed expression is True.\r\n\r\nSee the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.query.html)\r\n\r\n~~~python\r\n# queries all the values and returns where Seller is Carlos \r\ndf.query(\"Seller == 'Carlos'\")\r\n~~~\r\n\r\n![Image](../../../../images/post-2/17.png)\r\n\r\n<a id=\"df-col1\"></a>\r\n###### df['col']\r\nThis is on of the most common and simple ways to locate all the values on a entire column of a DataFrame. All you have to do is passing the columns names into the braces.\r\n\r\n~~~python\r\n# returns all the values into the column UnitPrice\r\ndf['UnitPrice']\r\n~~~\r\n\r\n![Image](../../../../images/post-2/18.png)\r\n\r\n<a id=\"df-col2\"></a>\r\n###### df.your_col\r\nFor a similar result as the previous locating method, you can also call the columns name as it is an attribute of the DataFrame.\r\n\r\n~~~python\r\n# returns all the values into the column UnitPrice\r\ndf.UnitPrice\r\n~~~\r\n\r\n![Image](../../../../images/post-2/18.png)\r\n\r\n#### Summarizing data\r\n\r\n<a id=\"describe\"></a>\r\n###### df.describe\r\nGenerate a decriptive statistics table. It includes measures such as mean, median, range, standard deviation, and more.\r\n\r\nSee the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html)\r\n\r\n~~~python\r\n# descriptive statistics with costumized percentiles\r\ndf.describe(percentiles=[0.2, 0.5, 0.8])\r\n~~~\r\n\r\n![Image](../../../../images/post-2/19.png)\r\n\r\n<a id=\"info\"></a>\r\n###### df.info\r\nPrint a summary of the DataFrame. This summary includes dtypes, columns, and non-null values.\r\n\r\nSee the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html)\r\n\r\n~~~python\r\n# prints summary info\r\ndf.info()\r\n~~~\r\n\r\n![Image](../../../../images/post-2/20.png)\r\n\r\n<a id=\"sum\"></a>\r\n###### df.sum\r\nReturn the sum of the values. You can access a column first to have the results for that specific column.\r\n\r\nSee the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sum.html)\r\n\r\n~~~python\r\n# returns the sum for the column Units\r\ndf.Units.sum()\r\n~~~\r\n\r\n![Image](../../../../images/post-2/21.png)\r\n\r\n<a id=\"count\"></a>\r\n###### df.count\r\nCount the cells with non-NA values for each row or column. NA values here are considered to be any *None*, *NaN*, *NaT* and *numpy.inf* values.\r\n\r\nSee the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.count.html)\r\n\r\n~~~python\r\n# counts non-null cells for each column\r\ndf.count()\r\n~~~\r\n\r\n![Image](../../../../images/post-2/22.png)\r\n\r\n<a id=\"min\"></a>\r\n###### df.min\r\nReturn the minimum of the values over the requested axis. You can either request for the minimum value of some row by passing `axis=0` or pass `axis=1` for the minimum over a column. \r\n\r\nSee the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.min.html)\r\n\r\n~~~python\r\n# minimum values over the columns\r\ndf.min()\r\n~~~\r\n\r\n![Image](../../../../images/post-2/23.png)\r\n\r\n<a id=\"max\"></a>\r\n###### df.max\r\nReturn the maximum of the values over the requested axis.\r\n\r\nSee the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.max.html)\r\n\r\n~~~python\r\n# maximum value over the column UnitPrice\r\ndf.UnitPrice.max()\r\n~~~\r\n\r\n![Image](../../../../images/post-2/24.png)\r\n\r\n<a id=\"mean\"></a>\r\n###### df.mean\r\nReturn the mean of the values over the requested axis.\r\n\r\nSee the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.mean.html)\r\n\r\n~~~python\r\n# mean value over the column UnitPrice\r\ndf.UnitPrice.mean()\r\n~~~\r\n\r\n![Image](../../../../images/post-2/25.png)\r\n\r\n<a id=\"median\"></a>\r\n###### df.median\r\nReturn the median of the values over the requested axis.\r\n\r\nSee the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.mean.html)\r\n\r\n~~~python\r\n# median value over the column UnitPrice \r\ndf.UnitPrice.median()\r\n~~~\r\n\r\n![Image](../../../../images/post-2/26.png)\r\n\r\n<a id=\"corr\"></a>\r\n###### df.corr\r\nCompute pairwise correlations of the DataFrame columns. It's very usefull to understand the correlation between two variables at a glance. A positive correlations indicates that the two variables varies on the same direction, while a negative correlation indicates that the two variables varies on opposite direction. On the other hand, a correlation of 0 indicates no real relationship between the variables.\r\n\r\nSee the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html)\r\n\r\n~~~python\r\n# chacking for existing correlation between numeric variables\r\ndf.corr()\r\n~~~\r\n\r\n![Image](../../../../images/post-2/27.png)\r\n\r\n## Summary\r\nWe covered up many useful functions of the Pandas python package. These are just a lightly demonstration on how this package can be used when working with data. For the intent of this post, the chosen example were pretty simple; but when we are working with large sets of data, or creating machine learning models, they are undoubtedly life savers.\r\n\r\nDon't feel confortable with these simple examples, see the documentation to have a better understanding on everything you are able to do with them, and try if for youself on your own dataset. You'll see how easier it will become once you give it a try and compare the results by yourself!\r\n\r\n---\r\n###### Reference Links:\r\n\r\n[www.codingame.com](https://www.codingame.com/playgrounds/52723/programacao-python-parte-3---prof--marco-vaz/pacote-pandas-dataframe#:~:text=Uma%20S%C3%A9rie%20Pandas%3A%20um%20array,uma%20coluna%20de%20um%20DataFrame)<br/>\r\n[www.pandas.pydata.org](https://pandas.pydata.org/docs/index.html)"}},{"path":"/posts/the-long-awaited-explanation-that-will-skill-you-on-telling-the-difference-among-ds-ai-ml-and-dl","page":{"__metadata":{"id":"content\\pages\\posts\\the-long-awaited-explanation-that-will-skill-you-on-telling-the-difference-among-ds-ai-ml-and-dl.md","source":"sourcebit-source-filesystem","sourceName":"pages","sourcePath":"content/pages","relSourcePath":"posts\\the-long-awaited-explanation-that-will-skill-you-on-telling-the-difference-among-ds-ai-ml-and-dl.md","relProjectPath":"content\\pages\\posts\\the-long-awaited-explanation-that-will-skill-you-on-telling-the-difference-among-ds-ai-ml-and-dl.md","modelType":"page","modelName":"post","modelLabel":"Post","urlPath":"/posts/the-long-awaited-explanation-that-will-skill-you-on-telling-the-difference-among-ds-ai-ml-and-dl"},"frontmatter":{"title":"The long-awaited explanation that will skill you on telling the difference among DS, AI, ML and DL","subtitle":"Because we all have been hearing a lot about Data Science, Artificial Intelligence, Machine Learning, and Deep Learning lately.","excerpt":"It's not surprising that most of us have already heard something about artificial intelligence at least once in our life, right? Although the first concepts of artificial intelligence were mentioned way before its creation, it is not a so recent research. But many of us still get a little confused when other terminologies begun to appear. So if you have ever felt yourself stuck when trying to tell one from another, stick with me on this post and I'll make it clear as water for you.","date":"2021-04-13","thumb_img_path":"images/post-1/01.jpg","thumb_img_alt":"DS, AI, ML, DL","content_img_path":"images/post-1/01.jpg","seo":{"title":"The long-awaited explanation that will skill you on telling the difference among DS, AI, ML and DL","description":"Because we all have been hearing a lot about Data Science, Artificial Intelligence, Machine Learning, and Deep Learning lately.","extra":[{"name":"og:type","value":"article","keyName":"property"},{"name":"og:title","value":"The long-awaited explanation that will skill you on telling the difference among DS, AI, ML and DL","keyName":"property"},{"name":"og:description","value":"Because we all have been hearing a lot about Data Science, Artificial Intelligence, Machine Learning, and Deep Learning lately.","keyName":"property"},{"name":"og:image","value":"images/post-1/01.jpg","keyName":"property","relativeUrl":true},{"name":"twitter:card","value":"summary_large_image"},{"name":"twitter:title","value":"The long-awaited explanation that will skill you on telling the difference among DS, AI, ML and DL"},{"name":"twitter:description","value":"Because we all have been hearing a lot about Data Science, Artificial Intelligence, Machine Learning, and Deep Learning lately."},{"name":"twitter:image","value":"images/post-1/01.jpg","relativeUrl":true}]},"layout":"post"},"markdown":"\nRaise your hand who haven't ever thought \"What if...\" for the idea of having real intelligent machines among us. Or, still, who haven't ever seen a movie staring human-like robots?\n\nHumans have been fascinated for so long about the idea of having machines performing tasks only we could make, that the first time an Artificial Intelligence (AI) was put into the screen was in 1927. However, it was only during the World War II that we had real studies beginning on this particular field - and that is almost a hundred years from now!\n\nIt was basically because of this urging will to prove that we could create a computer able to think, communicate, and act like a human being, that we now have the ultimate advances we see on our daily life. Smart assistants (like Siri and Alexa), self-driving cars, translators, voice and facial recognizer, disease mapping, plan autopilot, credit card fraud prevention, personalized online marketing, and so many others are all everyday examples of AI been used. But these, what we have, these are way far from be at the finish line.\n\nAs technology earns its own place on the market, researchers raised many other terminologies to support the AI continuous evolution. Machine Learning (ML), Deep Learning (DL), and Data Science (DS) are some of the terms we noticed were added on the AI's toolbox. As they have been mentioned a lot in recent years, it's time for us to understand how they differ from each other, but also how they complete each other.\n\n### Artificial Intelligence\nEverything that make it possible for a machine to present signs of what we call human intelligence can be told as AI. That is, the concepts of AI were created to name all the effort we have been making to make sure that this obsession we have under the question \"Can machines think?\" becomes less and less an unreality.\n\nAI is nothing but our desperate need to prove ourselves that we can create a computer that is not only able to look like a human, but also to act, speak, learn, and think like we do. So it's not only having a cold computer program calculating formulas and giving you the results anymore, it is also having this computer learning from experiences and exhibiting signs of intelligence by itself.\n\nToday, this is still a very abstract concept, since the only type of AI we have is a goal oriented. It means that it is created to be smart at a very specific task, but it doesn't have a proper conscious of what it's been doing.\n\n> A computer would deserve to be called intelligent if it could deceive a human into believing that it was human. <cite>The Turing Test. Alan Turing, 1950</cite>\n\nHowever, studies have been also trying to achieve a more general type of AI, where machines will be able to have its own set of understanding, interpreting, and acting; becoming unpredictable, and indistinguishable from a human being in some given situation.\n\nAlthough this is still not part of our reality, many advances in technology have been substantial for people to start believing that we could, one day, achieve this sort of intelligence. But for now, having computers performing specific tasks and showing, sometimes, better results than a human being... This could be already called madness a few years ago.\n\n### Machine Learning\n![Image](../../../images/post-1/02.png)\n***image*** *by author*\n\nIt was when studies started to get really deeper into discovering how to make machines learn like humans, that the first concept of ML was introduced. In 1959, this field appears as an evolution of the computating learning theory and the pattern recognition studies.\n\n> Machine learning is the field of study that gives computers the ability to learn without being explicitly programmed. <cite>Arthur Samuel, 1959</cite>\n\nScientists no longer wanted to only work on a trial and error system. They wanted to improve their ability to reach out a result that could be acceptably accurate. For that to happen, they saw the need to explore into the real meaning of learning; and so, later on, they come up with this concept that a human learning process could be put into some logic means through an algorithm, and explained to a machine. This machine would be then able to reproduce this \"logic\", they called the \"learning process\", and improve their results by retrieving errors as feedback. This so-fancy concept is nothing but what we already well-know as **learning through experience**.\n\nMany types of learning were developed on later years. But for now, we just need to understand that ML is a study that introduced the idea that we can make machines learn from experience - from data - without actually explicit programming their learning process and behavior.\n\nOnly by explaining the machines how to recognize patterns, researchers created a way to make computers develop a sufficient intelligence to take back their own errors and use them to improve their responses. This is Machine Learning. It is a subfield of AI, since it is the tool used to achieve many of the artificial intelligence applications we can see today. \n\n### Deep Learning\n![Deep Learning Interation](../../../images/post-1/03.png) \n***image*** *by author*\n\nTo be able to make the computer learning theory works with more complex kind of data, and to write the pipeline for the learning process as an algorithm that could interpret things like images or sounds, scientists did an awesome job recreating the human brain engine by simulating our neurons.\n\nI bet that sounds complicated, huh? Let me make it simpler.\n\nIn human beings, neurons are the basic structure responsible for carrying messages to and from our brain. Without them, we wouldn't be able to see, to hear, to feel, to taste, or to walk. It means that our brain needs to be entirely connected to our body in order for us to be able to do whatever thing we might want to do. And this \"connection\" is only possible because we have neurons - and many other structures - to carry electric impulses throughout our body. But machines don't have this connected body we do. So that's where the scientists came up with this insight.\n\n<cite>\"Maybe, we need to simulate a neuron!\"</cite>\n\nFrom that moment, when we found out that our brain worked just like our personal engine, researchers begin to create what they called the **artificial neuron**.\n\nNot all ML algorithms are powerful enough to work with *any* kind of information. Let's think of this in terms of our body. We may say that it's easier for us to understand that if we feel hungry we need to eat, than learning how to read when we still don't know what letters are for.\n\nSimilarly, some ML algorithms only work when the information we provide them are very organized and structured, just like our body is organized to know that eating is the natural action for when we feel hungry. This *little* issue brought up scientists the discussion about how to make machines understand data that are not so organized and structured, like images and audio files.\n\nThe artificial neurons were definitely a huge leap to the ML algorithms evolution. They are the concept of Deep Learning as it is.\n\nDL is a class of ML algorithms that use concepts way more complex, including multiple layers of data processing, to extract features from unorganized and non-structured data, that is, raw data. In other words, DL can be seen as an evolutionary complement of the ML algorithms, that has been used to bring us even closer to the initial idea of having general artificial intelligence created. Now, with the advances of DL algorithms, we can not only learn from basic set of data, but also break very complex data into small levels, and work with these smaller information into layers that will, at the end, bring all the processing together to come up with final features.\n\nBut you might be asking yourself <cite>\"Where does this Data Science thing go?\"</cite>\n\n### Data Science\nNow that we have all these technologies being created, it's time for us to think about its usability for good. And if you just though of DS as one of the ways to take advantage of these tools, you get it right, pal!\n\nData Science is an interdisciplinary field that involves a wide range of subjects, such as mathematics, statistics, computing processes, algorithms, business understanding, data analysis, and so on. The main goal of a *data scientist* is to extract valuable knowledge from information - called *data* -, in order to provide actionable insights in a broad range of application domain.\n\nTo be even clearer, DS is a field that can make use of the ML and DL concepts and tools to come up with insights that will turn into solutions for you.\n\nBut who might be *you*?\n\nYou could be anyone who need to solve a problem and who have a set of information, but still don't have a clue on how to use it. A data scientist will take her or his ability to work on big sets of data to manipulate, organize, and interpret them, and finally provide you with a clean image of what you need to turn your decision making process easier.\n\n### Summary\n![Image](../../../images/post-1/04.png)\n***image*** *by author*\n\nAnd to put all these information into one place, here is a final picture of the relationship among all these terminologies.\n\nBriefly, AI can be said as everything and every effort that make it possible for a machine to present signs of what we call human intelligence. Also, ML is a tool that we presented for the AI that allowed machines to learn by being exposed to external information. This way, we can understand that ML is part of the AI world.\n\nDigging a little bit deeper, we have DL that came as a complement to the ML algorithms to solve some restrictions when working with more complex type of data. That said, we can understand that DL is part of ML, being considered as a subclass within the whole package of ML algorithms.\n\nFinally, DS is well-known as a field of study that is able to take advantage of all of these tools, and combine them along with some mathematical, statistical, and analytical knowledge to extract valuable information for the most varied domains. \n\n---\n**Here you can have some more valuable information:** <br/>\n[Toward Data Science](https://towardsdatascience.com/understanding-the-difference-between-ai-ml-and-dl-cceb63252a6c)   (EN) <br/>\n[A Hist칩ria da Intelig칡ncia Artificial](https://www.youtube.com/watch?v=Lhu8bdmkMCM) (PT-BR)\n"}}]}
